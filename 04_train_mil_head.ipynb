{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2be9367d",
   "metadata": {},
   "source": [
    "\n",
    "# 04 â€” Train MIL Head (Presence/Absence)\n",
    "\n",
    "**Goal:** Train a lightweight MIL head on top of cached DINOv2 features.\n",
    "- Pool tile logits per image (max-pool by default).\n",
    "- Handle class imbalance with `pos_weight`.\n",
    "- Log basic metrics and save `mil_head.pt`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11457d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%pip -q install --extra-index-url https://download.pytorch.org/whl/cu121   torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0\n",
    "%pip -q install numpy pandas pyarrow scikit-learn tqdm mlflow==2.14.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b072b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, json, math, numpy as np, pandas as pd, torch\n",
    "from torch import nn, optim\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve, roc_auc_score\n",
    "import mlflow\n",
    "\n",
    "BASE = Path('/content')  # change if needed\n",
    "CACHE_DIR   = BASE/'cache/embeddings'\n",
    "MODEL_DIR   = BASE/'models'\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# If using MLflow with file storage, set once per session:\n",
    "os.environ.setdefault(\"MLFLOW_TRACKING_URI\", f\"file:{BASE/'runs'}\")\n",
    "mlflow.set_tracking_uri(os.environ[\"MLFLOW_TRACKING_URI\"])\n",
    "\n",
    "FEAT_DIM = 384   # DINOv2 ViT-S/14 feature dim\n",
    "POOLING = \"max\"  # \"max\" | \"lse\" | \"mean\"\n",
    "POS_WEIGHT = 3.0 # tune based on imbalance\n",
    "LR = 1e-3\n",
    "WD = 1e-4\n",
    "EPOCHS = 10\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46c7348",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import glob\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "def load_split(split):\n",
    "    paths = sorted(glob.glob(str(CACHE_DIR/f\"emb_{split}_*.parquet\")))\n",
    "    dfs = [pd.read_parquet(p) for p in paths]\n",
    "    df = pd.concat(dfs, axis=0, ignore_index=True) if dfs else pd.DataFrame()\n",
    "    return df\n",
    "\n",
    "train_df = load_split('train')\n",
    "val_df   = load_split('val')\n",
    "test_df  = load_split('test')\n",
    "for name, d in [('train',train_df),('val',val_df),('test',test_df)]:\n",
    "    print(name, d.shape, d['label'].value_counts().to_dict() if 'label' in d.columns else {})\n",
    "assert len(train_df), \"No training tiles found. Did you run previous notebooks?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f470656",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Group tiles by image_id, stack embeddings per image, keep image-level label\n",
    "def to_groups(df):\n",
    "    emb_cols = [c for c in df.columns if c.startswith('emb_')]\n",
    "    groups = {}\n",
    "    for img_id, g in df.groupby('image_id'):\n",
    "        feats = torch.tensor(g[emb_cols].values, dtype=torch.float32)\n",
    "        label = int(g['label'].iloc[0])\n",
    "        groups[img_id] = {'feats': feats, 'label': label}\n",
    "    return groups\n",
    "\n",
    "train_groups = to_groups(train_df)\n",
    "val_groups   = to_groups(val_df)\n",
    "test_groups  = to_groups(test_df)\n",
    "len(train_groups), len(val_groups), len(test_groups)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ffb322",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MILHead(nn.Module):\n",
    "    def __init__(self, d):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(d, 1)\n",
    "    def forward(self, tile_feats, pooling=\"max\"):\n",
    "        # tile_feats: [T,D]\n",
    "        logits = self.fc(tile_feats).squeeze(-1)  # [T]\n",
    "        if pooling==\"max\":\n",
    "            img_logit = logits.max()\n",
    "        elif pooling==\"lse\":\n",
    "            s=10.0; img_logit = torch.logsumexp(logits*s, dim=0)/s\n",
    "        else:\n",
    "            img_logit = logits.mean()\n",
    "        return img_logit, logits\n",
    "\n",
    "def eval_groups(head, groups):\n",
    "    head.eval()\n",
    "    y_true, y_prob = [], []\n",
    "    with torch.no_grad():\n",
    "        for g in groups.values():\n",
    "            feats = g['feats'].to(device)\n",
    "            logit, _ = head(feats, pooling=POOLING)\n",
    "            prob = torch.sigmoid(logit).item()\n",
    "            y_prob.append(prob); y_true.append(g['label'])\n",
    "    ap = average_precision_score(y_true, y_prob)\n",
    "    try:\n",
    "        auc = roc_auc_score(y_true, y_prob)\n",
    "    except Exception:\n",
    "        auc = float('nan')\n",
    "    return np.array(y_true), np.array(y_prob), ap, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f277ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mlflow.set_experiment(\"tortoise_mil_presence\")\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    head = MILHead(FEAT_DIM).to(device)\n",
    "    crit = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([POS_WEIGHT], device=device))\n",
    "    opt = optim.AdamW(head.parameters(), lr=LR, weight_decay=WD)\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        head.train()\n",
    "        total = 0.0\n",
    "        for g in tqdm(train_groups.values(), desc=f\"epoch {epoch}\"):\n",
    "            feats = g['feats'].to(device)\n",
    "            y = torch.tensor([g['label']], dtype=torch.float32, device=device)\n",
    "            logit, _ = head(feats, pooling=POOLING)\n",
    "            loss = crit(logit.unsqueeze(0), y.unsqueeze(0))\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "            total += loss.item()\n",
    "        yv, pv, ap, auc = eval_groups(head, val_groups)\n",
    "        print(f\"Epoch {epoch} loss={total/len(train_groups):.4f}  val AP={ap:.4f} AUC={auc:.4f}\")\n",
    "        mlflow.log_metric(\"train_loss\", total/len(train_groups), step=epoch)\n",
    "        mlflow.log_metric(\"val_ap\", ap, step=epoch)\n",
    "        if not math.isnan(auc): mlflow.log_metric(\"val_auc\", auc, step=epoch)\n",
    "\n",
    "    # Final eval on test\n",
    "    yt, pt, ap_t, auc_t = eval_groups(head, test_groups)\n",
    "    print(f\"TEST:  AP={ap_t:.4f}  AUC={auc_t:.4f}\")\n",
    "    mlflow.log_metric(\"test_ap\", ap_t)\n",
    "    if not math.isnan(auc_t): mlflow.log_metric(\"test_auc\", auc_t)\n",
    "\n",
    "    # Save model\n",
    "    out_path = MODEL_DIR/'mil_head.pt'\n",
    "    torch.save(head.state_dict(), out_path)\n",
    "    mlflow.log_artifact(str(out_path))\n",
    "    with open(MODEL_DIR/'model_card.json','w') as f:\n",
    "        json.dump({\n",
    "            \"feat_dim\": FEAT_DIM,\n",
    "            \"pooling\": POOLING,\n",
    "            \"pos_weight\": POS_WEIGHT,\n",
    "            \"epochs\": EPOCHS,\n",
    "            \"lr\": LR,\n",
    "            \"weight_decay\": WD\n",
    "        }, f, indent=2)\n",
    "    mlflow.log_artifact(str(MODEL_DIR/'model_card.json'))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
